version: '3'

services:
  text-gen-ts-server:
    build:
      context: .
      dockerfile: dockerfile.ts
    environment:
      MODEL_NAME: llama2-7b-chat
    ports:
      - "8085:8085"
      - "8086:8086"
    volumes:
      - ./model_store:/home/model-server/model_store
      - ./config:/home/model-server/config
    networks:
      - text-gen
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]

networks:
  text-gen:
